{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdtMUPBJwnrrPrRD2oyOwI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xBzYvhhd4LV"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 📌 뇌 MRI 기반 알츠하이머 보조진단 모델 성능 평가(1)\n",
        "# ================================\n",
        "\n",
        "# 0. 라이브러리 설치\n",
        "!pip install scikit-learn matplotlib seaborn pandas numpy\n",
        "\n",
        "# 1. 라이브러리 불러오기\n",
        "# 성능지표 계산(sklearn), 데이터처리(pandas, numpy), 시각화(matplotlib, seaborn)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, precision_recall_curve, auc, confusion_matrix, f1_score,\n",
        "    balanced_accuracy_score, matthews_corrcoef, brier_score_loss, roc_curve\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 2. CSV 파일 업로드\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # 업로드할 CSV 선택(CSV=데이터셋)\n",
        "\n",
        "# 업로드한 파일명 가져오기\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename)\n",
        "print(\"Columns in dataset:\", df.columns.tolist())\n",
        "\n",
        "# 3. 컬럼 설정 (필수/선택)\n",
        "# 반드시 필요한 컬럼: 실제 라벨(label), 모델 예측 확률(pred_prob)\n",
        "# 추가적으로 환자 ID, 시점(timepoint), subgroup 있으면 분석 확장 가능\n",
        "y_true = df['label'].values            # 실제 라벨\n",
        "y_pred_prob = df['pred_prob'].values   # 모델 예측 확률 (0~1)\n",
        "\n",
        "patient_id = df['patient_id'].values if 'patient_id' in df.columns else None\n",
        "timepoint = df['timepoint'].values if 'timepoint' in df.columns else None\n",
        "subgroup = df['subgroup'].values if 'subgroup' in df.columns else None\n",
        "\n",
        "# ================================\n",
        "# 4. 성능 지표 계산(AUC / PR-AUC)\n",
        "#  모델 성능을 수치로 확인 (AUC, PR-AUC, Sensitivity, Specificity 등)\n",
        "# - AUC: 모델이 환자/비환자 구분을 얼마나 잘하는지\n",
        "# - PR-AUC: 불균형 데이터(환자 수 적음)에 적합한 지표\n",
        "# - Sensitivity(민감도): 환자를 잘 잡아내는 비율\n",
        "# - Specificity(특이도): 정상인을 잘 구분하는 비율\n",
        "# - F1: Precision과 Recall의 조화 평균\n",
        "auc_score = roc_auc_score(y_true, y_pred_prob)\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n",
        "pr_auc_score = auc(recall, precision)\n",
        "print(f\"AUC: {auc_score:.3f}, PR-AUC: {pr_auc_score:.3f}\")\n",
        "\n",
        "# Threshold 기반 지표\n",
        "threshold = 0.5  # 임계값 (0.5 이상이면 알츠하이머로 분류)\n",
        "y_pred_label = (y_pred_prob >= threshold).astype(int)\n",
        "cm = confusion_matrix(y_true, y_pred_label)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "sensitivity = tp / (tp + fn) if (tp+fn) > 0 else 0\n",
        "specificity = tn / (tn + fp) if (tn+fp) > 0 else 0\n",
        "f1 = f1_score(y_true, y_pred_label)\n",
        "print(f\"Sensitivity: {sensitivity:.3f}, Specificity: {specificity:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "# 추가 지표\n",
        "# - Balanced Accuracy: 민감도+특이도 평균\n",
        "# - MCC: 양성/음성 균형 고려한 상관계수\n",
        "# - Brier Score: 예측확률과 실제 정답의 차이\n",
        "bal_acc = balanced_accuracy_score(y_true, y_pred_label)\n",
        "mcc = matthews_corrcoef(y_true, y_pred_label)\n",
        "brier = brier_score_loss(y_true, y_pred_prob)\n",
        "print(f\"Balanced Acc: {bal_acc:.3f}, MCC: {mcc:.3f}, Brier Score: {brier:.3f}\")\n",
        "\n",
        "# ================================\n",
        "# 5. 부트스트랩 95% CI 계단\n",
        "# 샘플을 여러 번 재추출해서(bootstrap) 지표의 신뢰구간 계산\n",
        "# 단순 점수뿐만 아니라 \"불확실성\" 범위도 확인 가능\n",
        "def bootstrap_ci(y_true, y_pred_prob, n_bootstrap=1000, alpha=0.05):\n",
        "    rng = np.random.default_rng(seed=42)\n",
        "    metrics_dict = {\"AUC\": [], \"PR-AUC\": [], \"Sensitivity\": [],\n",
        "                    \"Specificity\": [], \"F1\": [], \"Balanced Acc\": []}\n",
        "\n",
        "    for _ in range(n_bootstrap):\n",
        "        idx = rng.choice(len(y_true), len(y_true), replace=True)\n",
        "        y_true_bs = y_true[idx]\n",
        "        y_prob_bs = y_pred_prob[idx]\n",
        "        y_label_bs = (y_prob_bs >= 0.5).astype(int)\n",
        "\n",
        "        if len(np.unique(y_true_bs)) < 2:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            auc_bs = roc_auc_score(y_true_bs, y_prob_bs)\n",
        "            precision_bs, recall_bs, _ = precision_recall_curve(y_true_bs, y_prob_bs)\n",
        "            pr_auc_bs = auc(recall_bs, precision_bs)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        cm_bs = confusion_matrix(y_true_bs, y_label_bs)\n",
        "        if cm_bs.shape == (2,2):\n",
        "            tn, fp, fn, tp = cm_bs.ravel()\n",
        "            sens_bs = tp / (tp+fn) if (tp+fn) > 0 else 0\n",
        "            spec_bs = tn / (tn+fp) if (tn+fp) > 0 else 0\n",
        "        else:\n",
        "            sens_bs, spec_bs = np.nan, np.nan\n",
        "\n",
        "        f1_bs = f1_score(y_true_bs, y_label_bs)\n",
        "        bal_bs = balanced_accuracy_score(y_true_bs, y_label_bs)\n",
        "\n",
        "        metrics_dict[\"AUC\"].append(auc_bs)\n",
        "        metrics_dict[\"PR-AUC\"].append(pr_auc_bs)\n",
        "        metrics_dict[\"Sensitivity\"].append(sens_bs)\n",
        "        metrics_dict[\"Specificity\"].append(spec_bs)\n",
        "        metrics_dict[\"F1\"].append(f1_bs)\n",
        "        metrics_dict[\"Balanced Acc\"].append(bal_bs)\n",
        "\n",
        "    # CI 계산\n",
        "    ci_results = {}\n",
        "    for metric, values in metrics_dict.items():\n",
        "        if len(values) > 0:\n",
        "            lower = np.percentile(values, 100*alpha/2)\n",
        "            upper = np.percentile(values, 100*(1-alpha/2))\n",
        "            ci_results[metric] = (np.mean(values), lower, upper)\n",
        "    return ci_results\n",
        "\n",
        "ci_results = bootstrap_ci(y_true, y_pred_prob)\n",
        "print(\"\\n📌 Bootstrap 95% CI 결과\")\n",
        "for metric, (mean, lower, upper) in ci_results.items():\n",
        "    print(f\"{metric}: {mean:.3f} (95% CI {lower:.3f} ~ {upper:.3f})\")\n",
        "\n",
        "# ================================\n",
        "# 6. 시각화\n",
        "# ROC, PR, Confusion Matrix, Calibration Curve 시각화\n",
        "# - ROC: 모델이 환자/비환자 구분하는 능력\n",
        "# - PR Curve: 소수 클래스(환자)에 대한 모델 성능 강조\n",
        "# - Confusion Matrix: 실제/예측 비교 (오분류 확인)\n",
        "# - Calibration Curve: 예측 확률과 실제 발생률 일치 여부 확인\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC (AUC={auc_score:.3f})\")\n",
        "plt.plot([0,1],[0,1],'--',color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# PR Curve\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=f\"PR-AUC={pr_auc_score:.3f}\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix heatmap\n",
        "plt.figure()\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"NC\",\"AD\"], yticklabels=[\"NC\",\"AD\"])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Calibration Curve\n",
        "prob_true, prob_pred = calibration_curve(y_true, y_pred_prob, n_bins=10)\n",
        "plt.figure()\n",
        "plt.plot(prob_pred, prob_true, marker='o')\n",
        "plt.plot([0,1],[0,1],'--',color='gray')\n",
        "plt.xlabel(\"Predicted Probability\")\n",
        "plt.ylabel(\"Observed Frequency\")\n",
        "plt.title(\"Calibration Curve\")\n",
        "plt.show()\n",
        "\n",
        "# ================================\n",
        "# 7. Calibration Error (ECE)\n",
        "# 예측 확률이 실제와 얼마나 차이가 나는지 수치화\n",
        "# (낮을수록 모델의 확률값 신뢰 가능)\n",
        "bin_counts, _ = np.histogram(y_pred_prob, bins=10)\n",
        "ece = np.sum(bin_counts / len(y_pred_prob) * np.abs(prob_true - prob_pred))\n",
        "print(f\"ECE: {ece:.3f}\")\n",
        "\n",
        "# ================================\n",
        "# 8. Uncertainty (예시)\n",
        "# 불확실성 값 예시 (실제로는 Bayesian, MC Dropout 등 필요)\n",
        "# - 모델이 자신 없는 샘플(high uncertainty) 탐지 가능\n",
        "uncertainty = np.random.rand(len(y_pred_prob)) * 0.1\n",
        "high_uncertainty_idx = np.where(uncertainty > 0.08)[0]\n",
        "print(f\"High uncertainty samples: {high_uncertainty_idx}\")\n",
        "\n",
        "# ================================\n",
        "# 9. Subgroup 성능\n",
        "# 특정 그룹(성별, 나이대 등)별 성능 차이 분석\n",
        "# - 공정성/편향성 확인\n",
        "if subgroup is not None:\n",
        "    df_sub = pd.DataFrame({'y_true':y_true, 'y_pred_prob':y_pred_prob, 'subgroup':subgroup})\n",
        "    for g in df_sub['subgroup'].unique():\n",
        "        g_df = df_sub[df_sub['subgroup']==g]\n",
        "        if len(g_df['y_true'].unique()) > 1:\n",
        "            g_auc = roc_auc_score(g_df['y_true'], g_df['y_pred_prob'])\n",
        "            print(f\"Subgroup {g} AUC: {g_auc:.3f}\")\n",
        "\n",
        "# ================================\n",
        "# 10. Longitudinal Consistency\n",
        "# 한 환자를 시간(timepoint) 따라 추적 → 예측값의 일관성 체크\n",
        "# - 갑자기 큰 변화가 있으면 모델 안정성 문제 가능\n",
        "if patient_id is not None and timepoint is not None:\n",
        "    df_long = pd.DataFrame({'patient_id':patient_id, 'timepoint':timepoint, 'y_pred_prob':y_pred_prob})\n",
        "    for pid in df_long['patient_id'].unique():\n",
        "        series = df_long[df_long['patient_id']==pid].sort_values('timepoint')['y_pred_prob'].values\n",
        "        if len(series) > 1:\n",
        "            change = np.diff(series)\n",
        "            if np.any(np.abs(change) > 0.5):\n",
        "                print(f\"Patient {pid} has abrupt prediction change: {series}\")\n",
        "\n",
        "# ================================\n",
        "# 11. Quality Check (QC)\n",
        "# 데이터 품질 검증\n",
        "# - 결측치, 0~1 범위 밖 확률값 여부 확인\n",
        "df_qc = pd.DataFrame({'y_pred_prob':y_pred_prob})\n",
        "missing_count = df_qc.isna().sum().values[0]\n",
        "out_of_bounds = np.sum((df_qc['y_pred_prob']<0) | (df_qc['y_pred_prob']>1))\n",
        "print(f\"Missing values: {missing_count}, Out-of-bounds predictions: {out_of_bounds}\")\n"
      ]
    }
  ]
}